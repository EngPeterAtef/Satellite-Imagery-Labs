{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLhuXJIdJ4Pk","outputId":"466f9a7f-2351-4373-9dd6-1e289ba4a096"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Using cached sklearn-0.0.post1.tar.gz (3.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=81af2472265cb491fc110fa5cbbcbba7e05ea5408504272ad68282f45bcf7166\n","  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n","Successfully built sklearn\n","Installing collected packages: sklearn\n","Successfully installed sklearn-0.0.post1\n"]}],"source":["!pip install sklearn numpy"]},{"cell_type":"markdown","source":["You are given a dataset of iris flowers. The dataset has four features (sepal length, sepal width, petal length, and petal width) and three possible classes (setosa, versicolor, and virginica). Your task is to implement Maximum Likelihood Classification to predict the class of new flowers.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"PdCCDqylKEu0"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","# Load the data from the file\n","data = np.load('iris_data.npz')\n","X_train = data['X_train']\n","X_test = data['X_test']\n","y_train = data['y_train']\n","y_test = data['y_test']\n","\n","print(\"X_train\", X_train)\n","print(\"X_test\", X_test)\n","print(\"y_train\", y_train)\n","print(\"y_test\",y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulUW2E0iKaJz","outputId":"b6418848-dfec-4b59-d951-68cf08b94b99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train [[5.6 3.  4.1 1.3]\n"," [5.  3.4 1.6 0.4]\n"," [4.9 3.6 1.4 0.1]\n"," [6.7 3.3 5.7 2.5]\n"," [6.4 3.2 5.3 2.3]\n"," [5.4 3.9 1.3 0.4]\n"," [4.9 3.  1.4 0.2]\n"," [5.1 3.4 1.5 0.2]\n"," [4.4 2.9 1.4 0.2]\n"," [7.6 3.  6.6 2.1]\n"," [5.4 3.9 1.7 0.4]\n"," [6.7 3.1 5.6 2.4]\n"," [6.2 3.4 5.4 2.3]\n"," [7.2 3.  5.8 1.6]\n"," [5.  3.5 1.3 0.3]\n"," [6.7 2.5 5.8 1.8]\n"," [5.6 2.7 4.2 1.3]\n"," [7.4 2.8 6.1 1.9]\n"," [6.3 2.8 5.1 1.5]\n"," [5.  2.3 3.3 1. ]\n"," [4.6 3.6 1.  0.2]\n"," [6.1 2.9 4.7 1.4]\n"," [6.7 3.  5.  1.7]\n"," [6.  2.2 5.  1.5]\n"," [6.9 3.2 5.7 2.3]\n"," [5.1 2.5 3.  1.1]\n"," [5.  3.3 1.4 0.2]\n"," [6.3 3.3 4.7 1.6]\n"," [7.3 2.9 6.3 1.8]\n"," [6.5 2.8 4.6 1.5]\n"," [6.7 3.1 4.4 1.4]\n"," [5.6 3.  4.5 1.5]\n"," [6.4 2.8 5.6 2.1]\n"," [6.3 2.7 4.9 1.8]\n"," [5.7 2.6 3.5 1. ]\n"," [5.  3.5 1.6 0.6]\n"," [4.3 3.  1.1 0.1]\n"," [5.8 2.7 4.1 1. ]\n"," [5.5 2.6 4.4 1.2]\n"," [6.5 3.2 5.1 2. ]\n"," [6.7 3.1 4.7 1.5]\n"," [6.9 3.1 5.4 2.1]\n"," [5.4 3.  4.5 1.5]\n"," [5.5 2.4 3.7 1. ]\n"," [5.9 3.  5.1 1.8]\n"," [6.1 3.  4.9 1.8]\n"," [5.1 3.8 1.5 0.3]\n"," [5.2 4.1 1.5 0.1]\n"," [6.1 3.  4.6 1.4]\n"," [4.8 3.  1.4 0.1]\n"," [5.7 2.5 5.  2. ]\n"," [4.4 3.2 1.3 0.2]\n"," [5.7 3.8 1.7 0.3]\n"," [5.9 3.  4.2 1.5]\n"," [5.1 3.8 1.6 0.2]\n"," [5.4 3.7 1.5 0.2]\n"," [5.5 2.4 3.8 1.1]\n"," [5.8 4.  1.2 0.2]\n"," [6.5 3.  5.5 1.8]\n"," [4.6 3.4 1.4 0.3]\n"," [7.7 2.6 6.9 2.3]\n"," [4.7 3.2 1.3 0.2]\n"," [6.3 2.3 4.4 1.3]\n"," [7.7 3.  6.1 2.3]\n"," [5.1 3.3 1.7 0.5]\n"," [6.8 2.8 4.8 1.4]\n"," [5.1 3.7 1.5 0.4]\n"," [6.2 2.8 4.8 1.8]\n"," [6.1 2.8 4.7 1.2]\n"," [6.8 3.2 5.9 2.3]\n"," [5.  3.2 1.2 0.2]\n"," [5.8 2.7 5.1 1.9]\n"," [6.9 3.1 4.9 1.5]\n"," [5.  3.6 1.4 0.2]\n"," [6.4 2.7 5.3 1.9]]\n","X_test [[4.6 3.2 1.4 0.2]\n"," [7.2 3.6 6.1 2.5]\n"," [6.5 3.  5.8 2.2]\n"," [5.5 2.3 4.  1.3]\n"," [5.1 3.8 1.9 0.4]\n"," [6.3 2.5 5.  1.9]\n"," [5.9 3.2 4.8 1.8]\n"," [4.6 3.1 1.5 0.2]\n"," [5.7 4.4 1.5 0.4]\n"," [6.  2.7 5.1 1.6]\n"," [5.8 2.7 3.9 1.2]\n"," [5.7 2.9 4.2 1.3]\n"," [4.4 3.  1.3 0.2]\n"," [7.1 3.  5.9 2.1]\n"," [5.8 2.7 5.1 1.9]\n"," [6.  2.2 4.  1. ]\n"," [4.8 3.1 1.6 0.2]\n"," [4.9 2.4 3.3 1. ]\n"," [4.7 3.2 1.6 0.2]\n"," [6.5 3.  5.2 2. ]\n"," [4.9 3.1 1.5 0.1]\n"," [6.3 3.3 6.  2.5]\n"," [4.9 3.1 1.5 0.2]\n"," [6.  2.9 4.5 1.5]\n"," [5.6 2.8 4.9 2. ]\n"," [6.2 2.2 4.5 1.5]\n"," [6.9 3.1 5.1 2.3]\n"," [5.  2.  3.5 1. ]\n"," [7.  3.2 4.7 1.4]\n"," [4.8 3.4 1.6 0.2]\n"," [6.8 3.  5.5 2.1]\n"," [5.3 3.7 1.5 0.2]\n"," [4.9 2.5 4.5 1.7]\n"," [4.8 3.4 1.9 0.2]\n"," [5.1 3.5 1.4 0.3]\n"," [5.5 2.5 4.  1.3]\n"," [5.7 3.  4.2 1.2]\n"," [6.1 2.6 5.6 1.4]\n"," [6.2 2.9 4.3 1.3]\n"," [7.7 3.8 6.7 2.2]\n"," [5.2 3.5 1.5 0.2]\n"," [5.5 3.5 1.3 0.2]\n"," [5.4 3.4 1.5 0.4]\n"," [6.7 3.3 5.7 2.1]\n"," [6.6 2.9 4.6 1.3]\n"," [7.2 3.2 6.  1.8]\n"," [7.7 2.8 6.7 2. ]\n"," [6.3 3.4 5.6 2.4]\n"," [5.  3.  1.6 0.2]\n"," [5.7 2.8 4.1 1.3]\n"," [6.1 2.8 4.  1.3]\n"," [5.6 2.9 3.6 1.3]\n"," [6.6 3.  4.4 1.4]\n"," [5.1 3.5 1.4 0.2]\n"," [6.3 2.5 4.9 1.5]\n"," [6.4 2.9 4.3 1.3]\n"," [5.5 4.2 1.4 0.2]\n"," [5.7 2.8 4.5 1.3]\n"," [6.7 3.  5.2 2.3]\n"," [4.8 3.  1.4 0.3]\n"," [7.9 3.8 6.4 2. ]\n"," [6.4 2.8 5.6 2.2]\n"," [4.5 2.3 1.3 0.3]\n"," [5.8 2.6 4.  1.2]\n"," [6.  3.4 4.5 1.6]\n"," [6.4 3.1 5.5 1.8]\n"," [6.3 2.9 5.6 1.8]\n"," [5.6 2.5 3.9 1.1]\n"," [5.8 2.8 5.1 2.4]\n"," [5.2 3.4 1.4 0.2]\n"," [5.4 3.4 1.7 0.2]\n"," [5.2 2.7 3.9 1.4]\n"," [6.  3.  4.8 1.8]\n"," [5.  3.4 1.5 0.2]\n"," [6.4 3.2 4.5 1.5]]\n","y_train [1 0 0 2 2 0 0 0 0 2 0 2 2 2 0 2 1 2 2 1 0 1 1 2 2 1 0 1 2 1 1 1 2 2 1 0 0\n"," 1 1 2 1 2 1 1 2 2 0 0 1 0 2 0 0 1 0 0 1 0 2 0 2 0 1 2 0 1 0 2 1 2 0 2 1 0\n"," 2]\n","y_test [0 2 2 1 0 2 1 0 0 1 1 1 0 2 2 1 0 1 0 2 0 2 0 1 2 1 2 1 1 0 2 0 2 0 0 1 1\n"," 2 1 2 0 0 0 2 1 2 2 2 0 1 1 1 1 0 1 1 0 1 2 0 2 2 0 1 1 2 2 1 2 0 0 1 2 0\n"," 1]\n"]}]},{"cell_type":"markdown","source":["Implement Maximum Likelihood Classification"],"metadata":{"id":"5pKKG2kcM5jG"}},{"cell_type":"code","source":["# Implement a function that takes the mean and variance of a class, and a new sample, and returns the likelihood of the sample belonging to that class\n","def likelihood(mean, variance, x):\n","    pass\n","\n","def likelihood_classify(X_train, y_train, X_test):\n","  # TODO: Compute the mean and variance of each feature for each class in the training set\n","  means = []\n","  variances = []\n","  \n","  # TODO: print means and variances\n","\n","  # TODO: For each new sample in the testing set, compute the likelihood of belonging to each class, and predict the class with the highest likelihood\n","  # TODO: use previously implemented function\n","  y_pred = []\n","  \n","  return y_pred\n","\n","# TODO: Compute the accuracy of your classifier on the testing set\n","# TODO: print accuracy\n","\n","y_pred = likelihood_classify(X_train, y_train, X_test)\n","\n","accuracy = None\n","print(f\"Accuracy: {accuracy:.2f}\")"],"metadata":{"id":"VZc8p42zKaob"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implement Parallelepiped Classification"],"metadata":{"id":"IwqeAnw7LazU"}},{"cell_type":"code","source":["def parallelepiped_classifier(train_data, train_labels, test_data):\n","    # TODO: Calculate the class means and covariances for each class\n","    class_means = []\n","    class_covs = []\n","    \n","    # Classify the test data based on the Mahalanobis distance from the class means\n","    y_pred = []\n","    \n","    return y_pred\n","\n","# Apply the Parallelepiped Classifier to the iris dataset\n","y_pred = parallelepiped_classifier(X_train, y_train, X_test)\n","\n","# TODO: Calculate the accuracy of the classifier\n","\n","print(f\"Accuracy: {accuracy:.2f}\")"],"metadata":{"id":"EszbxHVUK4xy"},"execution_count":null,"outputs":[]}]}